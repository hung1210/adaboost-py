{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-08T15:02:13.995104Z","iopub.execute_input":"2022-04-08T15:02:13.996188Z","iopub.status.idle":"2022-04-08T15:02:14.027647Z","shell.execute_reply.started":"2022-04-08T15:02:13.996025Z","shell.execute_reply":"2022-04-08T15:02:14.026713Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pandas\nimport numpy as numpy\n\ndata = pandas.read_csv('../input/spamemail123/spam_email123.csv')\nonlydata=data.loc[:,'make':'cap_total']\nonlydata.describe(include='all')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:14.029426Z","iopub.execute_input":"2022-04-08T15:02:14.029898Z","iopub.status.idle":"2022-04-08T15:02:14.225144Z","shell.execute_reply.started":"2022-04-08T15:02:14.029856Z","shell.execute_reply":"2022-04-08T15:02:14.224258Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX=onlydata.values\nClass=data.values[:,57]\ny=numpy.zeros((Class.size))\ny[Class=='spam']=1\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.45, random_state = 0)\n# Standardize the x_train and x_test datasets\nstd_scaler = preprocessing.StandardScaler().fit(X_train)\nX_train_scaled = std_scaler.transform(X_train)\nX_test_scaled = std_scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:14.226651Z","iopub.execute_input":"2022-04-08T15:02:14.226860Z","iopub.status.idle":"2022-04-08T15:02:15.364903Z","shell.execute_reply.started":"2022-04-08T15:02:14.226834Z","shell.execute_reply":"2022-04-08T15:02:15.363934Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\npca = PCA(n_components=2)\nfig, (plttrain, plttest) = plt.subplots(1, 2)\ndatavl1=pca.fit_transform(X_train_scaled)\nA1=datavl1[(y_train==1)]\nA2=datavl1[(y_train==0)]\nplttrain.set_title('Train values :'+ str(X_train_scaled.shape))\nplttrain.scatter(A1[:,0],A1[:,1],c=\"Black\",marker='o')\nplttrain.scatter(A2[:,0],A2[:,1],c=\"Pink\",marker='+')\nplttrain.legend(['label 1','label 0'])\ndatavl2=pca.fit_transform(X_test_scaled)\nA11=datavl2[(y_test==1)]\nA12=datavl2[(y_test==0)]\nplttest.set_title('Test values :'+str(X_test_scaled.shape))\nplttest.scatter(A11[:,0],A11[:,1],c=\"Black\",marker='o')\nplttest.scatter(A12[:,0],A12[:,1],c=\"Pink\",marker='+')\nplttest.legend(['label 1','label 0'])\nplt.savefig('lettersCG_Xtraintext.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:15.366043Z","iopub.execute_input":"2022-04-08T15:02:15.366295Z","iopub.status.idle":"2022-04-08T15:02:16.265062Z","shell.execute_reply.started":"2022-04-08T15:02:15.366266Z","shell.execute_reply":"2022-04-08T15:02:16.264216Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\npca= PCA(n_components=2)\n# fig, (plttrain, plttest) = plt.subplots(1, 2)\ndatavlx=pca.fit_transform(X)\nAx1=datavlx[(y==1)]\nAx2=datavlx[(y==0)]\nplt.title('Train values :'+ str(X.shape))\nplt.scatter(Ax1[:,0],Ax1[:,1],c=\"Black\",marker='o')\nplt.scatter(Ax2[:,0],Ax2[:,1],c=\"Pink\",marker='+')\nplt.legend(['label 1','label 0'])\nplt.savefig('lettersCG_X.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:16.267728Z","iopub.execute_input":"2022-04-08T15:02:16.268349Z","iopub.status.idle":"2022-04-08T15:02:16.745794Z","shell.execute_reply.started":"2022-04-08T15:02:16.268303Z","shell.execute_reply":"2022-04-08T15:02:16.745146Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class RatingModel:\n    def __init__(self, y_, y_Pr):\n      self.y_=y_\n      self.y_Pr=y_Pr\n      self.TN=np.size(y_Pr[(y_Pr==-1)&(y_==y_Pr)])\n      self.FN=np.size(y_Pr[(y_Pr==-1)&(y_!=y_Pr)])\n      self.TP=np.size(y_Pr[(y_Pr==1)&(y_==y_Pr)])\n      self.FP=np.size(y_Pr[(y_Pr==1)&(y_!=y_Pr)])\n      self.y_[self.y_==0]=-1\n      self.y_Pr[self.y_Pr==0]=-1\n      # assert self.y_.set={1, -1}\n      # assert self.y_Pr.set={1, -1}\n    def __rep__():\n        return \"\"\n    def accur_Error(self, y_, y_Pr):\n        rs=(self.TP+self.TN)/(y_.size)\n        return [rs,(1-rs)]\n    def sensitivity(self):\n        P=np.size(self.y_[self.y_==1])\n        return (self.TP)/(P)\n    def specificity(self):\n        N=np.size(self.y_[self.y_==-1])\n        return (self.TN)/(N)\n    def precision(self):\n        rs=self.TP+self.FP\n        return (self.TP)/(rs)\n    def recall(self):\n        rs=self.TP+self.FN\n        return (self.TP)/(rs)\n    def rating(self):\n        return [self.accur_Error(self.y_, self.y_Pr), self.sensitivity(), self.specificity(), self.precision(), self.recall()]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:16.747204Z","iopub.execute_input":"2022-04-08T15:02:16.747688Z","iopub.status.idle":"2022-04-08T15:02:16.759339Z","shell.execute_reply.started":"2022-04-08T15:02:16.747647Z","shell.execute_reply":"2022-04-08T15:02:16.758566Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class DecisionStump:\n    def __init__(self, T=100):\n        self.T = T\n        pass\n\n    def fit(self, X: np.ndarray, y: np.ndarray, sample_weight: np.ndarray):\n        T = self.T\n        W=sample_weight\n        nrow, ncol = X.shape\n        assert nrow == y.size\n\n        bestn = 0\n        bestd = 1\n        bestp = 0\n        minerr = W.sum()\n        for i in range(ncol):\n            err, d, p = self._optimize(X[:, i], y, W, T)\n            if err < minerr:\n                minerr = err\n                bestn = i\n                bestd = d\n                bestp = p\n        \n        self.features = ncol\n        self.bestn = bestn\n        self.bestd = bestd\n        self.bestp = bestp\n\n        return self\n\n    def _optimize(self, X, y, W, T):\n        X = X.flatten()\n        min_x, max_x = X.min(), X.max()\n        len_x = max_x - min_x\n        \n        bestd = 1\n        bestp = min_x\n        minerr = W.sum()\n\n        if len_x > 0.0:\n            for p in np.arange(min_x, max_x, len_x/T):\n                for d in [-1, 1]:\n                    gy = np.ones((y.size))\n                    gy[X*d < p*d] = -1\n                    err = np.sum((gy != y)*W)\n                    if err < minerr:\n                        minerr = err\n                        bestd = d\n                        bestp = p\n\n        return minerr, bestd, bestp\n\n    def predict(self, test_set : np.ndarray):\n        nrow, ncol = test_set.shape\n\n        assert ncol == self.features\n\n        icol = test_set[:, self.bestn]\n        h = np.ones((nrow))\n        h[icol*self.bestd < self.bestp*self.bestd] = -1\n        return h","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:16.760303Z","iopub.execute_input":"2022-04-08T15:02:16.760993Z","iopub.status.idle":"2022-04-08T15:02:16.787678Z","shell.execute_reply.started":"2022-04-08T15:02:16.760958Z","shell.execute_reply":"2022-04-08T15:02:16.786631Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class AdaBoost:\n    def __init__(self , T, hmodel = DecisionStump()):\n        self.T=T\n        self.hmodel=hmodel\n    def fit(self, X: np.ndarray, y_: np.ndarray, verbose=False):\n      n = X.shape[0]\n      T = self.T\n      y=y_\n      y[y==0]=-1\n    # init numpy arrays\n      self.D = np.zeros(shape=(T, n))\n      self.h = np.zeros(shape=T, dtype=object)\n      self.alpha = np.zeros(shape=T)\n      self.errors = np.zeros(shape=T)\n      self.ratting = np.zeros(shape=(T,2))\n\n      # initialize weights uniformly\n      self.D[0] = np.ones(shape=n) / n\n\n      for t in range(T):\n          # fit  weak learner\n          D_ = self.D[t]\n          h_ = DecisionStump(60)\n          h_ = h_.fit(X, y, D_)\n\n          # calculate error and stump weight from weak learner prediction\n          Pr_ = h_.predict(X)\n          error_ = D_[(Pr_ != y)].sum()# / n\n          alpha_ = np.log((1 - error_) / error_) / 2\n\n          # update sample weights\n          D_new = (\n              D_ * np.exp(-alpha_ * y * Pr_)\n          )\n          \n          D_new /= D_new.sum()\n\n          # If not final iteration, update sample weights for t+1\n          if t+1 < T:\n              self.D[t+1] = D_new\n\n          # save results of iteration\n          self.h[t] = h_\n          self.alpha[t] = alpha_\n          self.errors[t] = error_\n          # ae=np.array([0,0])\n          if t>0:\n            Pr_temp=self.predictmodul(X,t)\n            modelra=RatingModel(y, Pr_temp)\n            self.ratting[t,:]=modelra.accur_Error(y, Pr_temp)\n          if verbose: print('Training {0}-th weak classifier: accuracy={1}, error={2}'.format (t, self.ratting[t,0], self.ratting[t,1]))\n      return self\n    def predict(self, X):\n        Pr_ = np.array([h_.predict(X) for h_ in self.h])\n        return np.sign(np.dot(self.alpha, Pr_))\n    def predictmodul(self, X, i):\n        h_temp=self.h[:i]\n        alpha_temp=self.alpha[:i]\n        Pr_ = np.array([h_.predict(X) for h_ in h_temp])\n        return np.sign(np.dot(alpha_temp, Pr_))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:16.789095Z","iopub.execute_input":"2022-04-08T15:02:16.789812Z","iopub.status.idle":"2022-04-08T15:02:16.811167Z","shell.execute_reply.started":"2022-04-08T15:02:16.789771Z","shell.execute_reply":"2022-04-08T15:02:16.809607Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model=AdaBoost(35)\nmodel=model.fit(X_train_scaled, y_train,  True )\nPr=model.predict( X_test_scaled)\nPr[(Pr==0)]=-1\n# print(Pr, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:16.815309Z","iopub.execute_input":"2022-04-08T15:02:16.816054Z","iopub.status.idle":"2022-04-08T15:02:24.766322Z","shell.execute_reply.started":"2022-04-08T15:02:16.816018Z","shell.execute_reply":"2022-04-08T15:02:24.765239Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"ra_Xtest = np.zeros(shape=(model.T,2))\nfor i in range(1,model.T):\n  Pr_i=model.predictmodul(X_test_scaled,i)\n  modelra=RatingModel(y_test, Pr_i)\n  ra_Xtest[i,:]=modelra.accur_Error(y_test, Pr_i)\nra_Xtrain = np.zeros(shape=(model.T,2))\nfor i in range(1,model.T):\n  Pr_i=model.predictmodul(X_train_scaled,i)\n  modelra=RatingModel(y_train, Pr_i)\n  ra_Xtrain[i,:]=modelra.accur_Error(y_train, Pr_i)\niter=range(model.T)\nplt.plot(iter,ra_Xtest[:,0],'y-', label='Test accuracy')\nplt.plot(iter,ra_Xtest[:,1],'r-', label='Test error')\nplt.plot(iter,ra_Xtrain[:,0],'y--', label='Train accuracy')\nplt.plot(iter,ra_Xtrain[:,1],'r--', label='Train error')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:24.772051Z","iopub.execute_input":"2022-04-08T15:02:24.772836Z","iopub.status.idle":"2022-04-08T15:02:25.056261Z","shell.execute_reply.started":"2022-04-08T15:02:24.772777Z","shell.execute_reply":"2022-04-08T15:02:25.055327Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"sumerror=0;\ny_new=y_test\ny_new[y_new==0]=-1\n# for i in range(y_new.shape[0]):\n#   if y_new[i]!=Pr[i]: \n#     sumerror+=1\nsumerror=np.size(y_new[Pr!=y_new])\ngT1=datavl2[(Pr==1)]\ngT0=datavl2[(Pr==-1)]\ngF1=datavl2[(y_new!=Pr)&(Pr==1)]\ngF0=datavl2[(y_new!=Pr)&(Pr==-1)]\nplt.title('Test values errors :'+str(sumerror)+'/ '+str(X_test_scaled.shape[0]))\nplt.scatter(gT1[:,0],gT1[:,1],c=\"Pink\", marker='o')\nplt.scatter(gT0[:,0],gT0[:,1],c=\"Red\", marker='+')\nplt.scatter(gF1[:,0],gF1[:,1], c=\"black\", marker='o')\nplt.scatter(gF0[:,0],gF0[:,1], c=\"black\", marker='+')\nplt.legend(['Dự đoán đúng 1', 'Dự đoán đúng 0', 'Dự đoán sai'])\nplt.savefig('lettersCG_XtextError.png')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T15:02:25.058087Z","iopub.execute_input":"2022-04-08T15:02:25.058322Z","iopub.status.idle":"2022-04-08T15:02:25.382475Z","shell.execute_reply.started":"2022-04-08T15:02:25.058295Z","shell.execute_reply":"2022-04-08T15:02:25.381543Z"},"trusted":true},"execution_count":11,"outputs":[]}]}